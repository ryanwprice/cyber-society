---
title: Our Digital Selves Do Not Need Fixing
lname: Emmens
fname: Ashley
email: emmensa@mcmaster.ca
web: linkedin.com/in/ashley-emmens
image-description: Photo by NeONBRAND on Unsplash
bio: A Communication Studies student at McMaster University.
---

It is my opinion that our "digital selves" and how we interact online will never be able to mirror our actual selves and how we interact offline, and that is okay. However, some companies are trying to find ways to improve social media so that it mirrors reality better but I think that the harder we try to do this, the further away from reality we get. Sometimes when people post on social media, they share athought or comment that is offensive or hurtful to their friends, just as they say these things in real life (Bogost, 2019). Social media may not have the same mechanisms in real life to let us know when it is appropriate or not to discuss something - for example, we cannot see the facial reactions of the people reading the post (Bogost, 2019). Although it doesn't have the same type of cues, social media has its own type of social cues that work well for its platform. For example, if you post an unflattering picture or uncommon opinion, you will likely get fewer likes. You do not need the subtle social cues of the real world to know when you post something unfavourable. When I see a post from a friend that I disagree with, I am not upset that my only options are to ignore it or dislike or avoid giving it a like. I do not have an overwhelming need or wish to express my dislike in other ways and I doubt that others do either. Bogost suggests that social media apps are awful the way they are now (Bogost, 2019). Social media apps are not awful they way they are and they serve their intended purpose.

Rana el Kaliouby, the CEO of Affectiva, an artificial-intelligence start-up, has suggested that the Artificial Intelligence (AI) system her company has created can be used to give feedback on our posts, such as the number of people upset about what you shared (Bogost, 2019). Rana el Kaliouby imagines a world where it is possible to read the emotional reactions of your Facebook friends' real faces (Bogost, 2019). Her company's AI system would attempt to pinpoint "facial action units" according to categories created by psychologists Paul Ekman and Wallace V. Friesen (Bogost, 2019). The response of viewers can be expressed as an abstract rendition, possibly in the form of emoji's, that indicates the approximate emotional response of people who look at the post (Bogost, 2019). However, this does not mirror life, as we don't have a system that categorizes our friend's facial reactions, or that provides us with an average response to what we say. Furthermore, in-real-life, different opinions from different people carry different weights, so an average is not useful. It may be important to us that our best friend liked our post, and unimportant that an acquaintance was upset by it. As I've mentioned, this sort of feedback is not necessary as it already exists (for example, in a lesser number of likes than normal). Currently, social media platforms like Facebook and Twitter have like functions or emoji reactions (Bogost, 2019). The fact that these reactions are self-reported actually allows us to save face because we are not forced to express our true reactions that may hurt someone. In real life, we protect feelings by lying, for example, we tell our friend she looks good in the picture she posted when that is not how we actually feel. When using the proposed AI system, if you react with disgust, she will know this, and it will hurt her feelings. Therefore, the AI system in some aspects can worsen social costs.

el Kaliouby company attempted to produce a consumer-oriented service, and when it failed due to lack of traction, blamed its failure on the fact that it is hard to launch something in a crowded market (Bogost, 2019). I believe that this failure is not actually due to market saturation, but instead due to a lack of demand for a service such as that. Machine-learning has already been applied to social media platforms like Facebook for personalization of content, arguably a simpler task, and this has already been controversial in the design community and still is flawed with some instances of poor execution, causing frustrating experiences (Baker, n.d.).

Although the software may be able to understand emotional responses, it will fail to take into account other things such as attention, interest level, and importantly, mood (Baker, n.d.). One way that the Containing Multitudes article images we could attempt to mirror real-world social dynamics in a user interface would be to  "present a user with hundreds of sliders, checkboxes, and options for responding to posts or reacting to another user," however, acknowledges that would be highly ineffective and severely overburden the user with administrative tasks (Baker, n.d.). Therefore, there is no effective way to mirror reality online, nor should we try to.

The author of this article states that the "potential rewards of this technology are no less significant than its privacy risks" but does not go into any detail discussing the privacy risks, therefore not proving the potential rewards are actually as significant as the risks (Bogost, 2019). The article suggests that the social or safety benefit of the technology is worth the trade-off in privacy and surveillance (Bogost, 2019). It is not fair for companies to make this type of determination. People tend to value their privacy to a very high degree and not let many things get in the way of it, especially technology.

The Containing Multitudes article asks the question "What features of evolved real-world individual and community social dynamics can we replicate with current technology?" and the AI system proposed by Rana el Kaliouby thinks it provides an answer to that, but it is flawed (Baker, n.d.). There is no way to replicate, real-world social dynamics in current technology, instead, we should treat the online world as its own type of reality with its own rules and own types of negotiating behaviours.


References

Baker, M. (n.d.). Containing Multitudes. Retrieved from https://alwaysreadthemanual.com/read/issues/5/mills-baker/article.html.

Bogost, I. (2019, June 25). What If Social Media Could Tell You When You're Mean? Retrieved from https://www.theatlantic.com/technology/archive/2019/06/social-app-tells-you-when-youre-mean/592480/.


